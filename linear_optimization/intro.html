<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <link href="https://adriann.github.io/feed.rss" rel="alternate" type="application/rss+xml" title="What's new on adriann.github.io" />
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Adrian Neumann (adrian_neumann@gmx.de)" />
  <title>Introduction</title>
  <style type="text/css">
  .displayequation{margin-left:auto;margin-right:auto;}
  </style>
  <style>
  .caption{font-size:66%;text-align:right;}
  .figure{float:right;padding-bottom:1em;padding-left:1em;}
  .figure>img{display:block;margin:0 auto;}
  .footnotes{font-size:80%;}
  .block{border-left:1ex solid gray;padding-left:2em;}
  li{padding:0.25em;}
  a:hover{text-shadow: 0 0 5px;}
  body{font-family:sans-serif;max-width:100ex;padding-left:3em;padding-right:2em;}
  code{font-family:Consolas, Inconsolata, Monaco, monospace;}
  p{text-align:justify;}
  </style>
</head>
<body>
<div id="header">
<h1 class="title">Introduction</h1>
</div>
<p>Although it’s called “Programming”, Linear Programming has little to do with what you’d call programming today. The term dates back to a time where programming had more to with filling out tables than writing code.</p>
<p>Let me first hit you with the formal definition. In Linear Programming we have a number of real variables <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">x_1, \ldots, x_n</annotation></semantics></math>, and some linear value function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">f(x_1, \ldots, x_n)</annotation></semantics></math> we want to maximize (or minimize). The interesting part is the set of constraints on the variables we need to satisfy (otherwise optimizing <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math> would be trivial). The constraints are a set of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math> linear inequalities</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mrow><mi>j</mi><mn>1</mn></mrow></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mi>…</mi><mo>+</mo><msub><mi>a</mi><mrow><mi>j</mi><mi>n</mi></mrow></msub><msub><mi>x</mi><mi>n</mi></msub><mo>≤</mo><msub><mi>b</mi><mi>j</mi></msub><mspace width="2.0em"></mspace><msub><mi>a</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub><mo>,</mo><msub><mi>b</mi><mi>j</mi></msub><mo>∈</mo><mtext mathvariant="normal">R</mtext></mrow><annotation encoding="application/x-tex">a_{j1}x_1 + \ldots + a_{jn} x_n \leq b_j \qquad a_{ji},b_j \in \mbox{R}</annotation></semantics></math></p>
<p>for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">1\leq j\leq m</annotation></semantics></math>.</p>
<p>Now this likely seems difficult to you and you can’t see any obvious applications. Good. This way you can feel very smart once you understand it. Let’s proceed with an examples.</p>
<p>In the Diet Problem we want to find a cheap diet, say for the military. <a href="http://www.jstor.org/stable/25061369">This is one of the original applications of Linear Programming.</a> and dates back to the first half of the twentieth century.</p>
<p>Let’s introduce a mathematical model of a diet. We have <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> types of food and each foodstuff has <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math> different features, e.g. calories, price, different vitamins, etc. A diet, that is, a solution to our problem, consists of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math> (kilograms) of food <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> (say per month). The <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math> are the variables we want to find.</p>
<p>We want to optimize the price of our diet, so our objective function is the sum of the amount of food <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>, times the cost, cost(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>), for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">i=1,\ldots, n</annotation></semantics></math>. This is a linear function, because we don’t multiply two or more variables with each other. The cost of food <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> is not a variable, it’s just a number.</p>
<p>The cheapest diet is a starvation diet where you don’t eat anything, but of course we want a diet that is cheap and nutritious, so we need to constrain our solution. To do so we can introduce a number of constraints. Things like</p>
<ul>
<li>our diet must have at least 2000 calories a day</li>
<li>our diet must have at least the recommended amount of each vitamin</li>
<li>our diet must have at most the safe amount of salt</li>
</ul>
<p>As you can easily see these are all linear constraints, since for example the calories of each food in our diet simply add up. Since we have a linear cost function and a set of linear constraints, our model is in the form of a linear program. Using a piece of software called an LP solver we can find an optimal solution, that is a diet that is as cheap as possible while not violating any of our nutritiousness constraints. I will later explain how these programs work.</p>
<p>One has to be somewhat careful in designing these constraints, otherwise the solutions one gets can be amusingly impractical. The article I linked at the beginning contains a funny anecdote about this.</p>
<p>Note that we implicitly assumed that we can have any real number as the amount of food we eat. This is bad because we might get a solution where we have to eat negative amounts of some food (Too many calories in your diet? Just try this one trick and eat negative amounts of butter!). We can fix this with additional constraints <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x_i \ge 0</annotation></semantics></math>. Another problem is that some foods are not easily divided into small parts. It’s hard to eat 0.213kg of bananas a day without wasting some bananas. We’d like to have integer values for some of the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>. This can not be expressed with additional linear constraints<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> and you’ll see later on that imposing integrality constraints on our solution makes the problem a lot harder.</p>
<p>But note that dropping some constraints, notably integrality constraints, can only improve the cost of the optimal solution. So a solution with fractional variables can be used as a lower bound for the optimal cost. This is an extremely useful insight if you want to prove bounds on the quality of some approximation algorithm you just came up with. Fractional solutions can also be a good start for finding true solution to your problem, for example by rounding.</p>
<p>Solving a fractional LP and then rounding is often an easy way to get an approximate solution to a problem that is hard to solve exactly. But of course it’s not the only way. The field of approximation algorithms tries to find approximate solutions, typically for NP-complete problems. It also contains hardness results. Some problems are not only hard to solve exactly, they’re <em>also</em> hard to approximately solve. This is interesting because it gives us a more nuanced view of the difficulty of hard problems. The typical CS undergraduate will stop after a NP-completeness proof, because NP-complete problems are a) all hard and b) all about the same, after all once you can solve one, you can solve them all. Approximation theory reveals a whole world of nuance between different NP-complete problems.</p>
<p>Let’s see an example of a simple approximation algorithm.</p>
<p>Suppose we have <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> jobs that take times <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mi>…</mi><msub><mi>w</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">w_1 \ldots w_n</annotation></semantics></math> to complete and two machines that can work of them. We want to assign the jobs to the machines such that the total running time is minimized. This problem is NP-complete (reduction e.g. Knapsack). Let’s try a heuristic solution and see how good it performs. The natural approach is assigning the first job to the first machine and then assigning the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">i+1</annotation></semantics></math>-th job to the machines that has less work among the first <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> jobs. Note that this algorithm doesn’t need to know all the jobs before hand, it can handle jobs as they come in. This is sometimes a very desirable property of an algorithm. Algorithms of this kind are called <em>online algorithms</em>.</p>
<p>How does a schedule such computed compare to the optimal schedule that might use arbitrarily clever algorithms and advance knowledge of all jobs? Every sensible algorithm is at least within a factor of two of the optimal schedule. Since we only have two machines we can’t do more than two units of work concurrently. The heuristic I described above is however better. It takes at most <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">3/2</annotation></semantics></math> the time of an optimal schedule. We say it’s a <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">3/2</annotation></semantics></math> approximation.</p>
<p>The proof is easy: Let <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><annotation encoding="application/x-tex">w_{max}</annotation></semantics></math> be the size of the maximal job and let <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> be the total amount of work we have to do. No schedule can be faster than <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><annotation encoding="application/x-tex">w_{max}</annotation></semantics></math>. Hence the time <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="normal">opt</mtext><annotation encoding="application/x-tex">\mbox{opt}</annotation></semantics></math> an optimal schedule takes can be bounded as <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">opt</mtext><mo>≥</mo><mo>max</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>w</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo>,</mo><mi>W</mi><mi>/</mi><mn>2</mn><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mbox{opt} \geq \max (w_{max}, W/2)</annotation></semantics></math>. Consider the situation before the last job is assigned. The size of the already assigned jobs is <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>−</mo><msub><mi>w</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">W-w_n</annotation></semantics></math> so the less loaded machine (wlog 2) has a load at most <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>W</mi><mo>−</mo><msub><mi>w</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">)</mo><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">(W-w_n)/2</annotation></semantics></math>. Assuming machine 2 determines the total length, the algorithm produces a schedule of length</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mo stretchy="false" form="prefix">(</mo><mi>W</mi><mo>−</mo><msub><mi>w</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><mn>2</mn></mfrac><mo>+</mo><msub><mi>w</mi><mi>n</mi></msub><mo>≤</mo><mi>W</mi><mi>/</mi><mn>2</mn><mo>+</mo><msub><mi>w</mi><mi>n</mi></msub><mi>/</mi><mn>2</mn><mo>≤</mo><mtext mathvariant="normal">opt</mtext><mo>+</mo><mtext mathvariant="normal">opt</mtext><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">\frac{(W-w_n)}{2} + w_n \leq W/2+w_n/2 \leq \mbox{opt} + \mbox{opt}/2</annotation></semantics></math></p>
<p><a href="fourier-motzkin.html">Click here to proceed to the next part, Solving LPs with Fourier Motzkin</a><br />
<a href="../linear_optimization.html">Click here to go back to the index</a></p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>unless P=NP, I guess…<a href="#fnref1">↩</a></p></li>
</ol>
</div>
<hr/>
<div style="display:flex;justify-content:space-between;font-size:80%">
<p>CC-BY-SA <a href="mailto:adrian_neumann@gmx.de">Adrian Neumann</a> (PGP Key <a href="https://adriann.github.io/ressources/pub.asc">A0A8BC98</a>)</p>
<p><a href="http://adriann.github.io">adriann.github.io</a></p>
<p><a href="https://adriann.github.io/feed.rss">RSS</a></p>
</div>
</body>
</html>
